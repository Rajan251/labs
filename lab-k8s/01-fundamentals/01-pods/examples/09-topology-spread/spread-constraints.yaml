# Pod Topology Spread Constraints
# Control how pods are spread across topology domains (zones, nodes, etc.)

# Example 1: Spread across zones
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-spread-zones
spec:
  replicas: 6
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      # Spread pods evenly across availability zones
      topologySpreadConstraints:
      - maxSkew: 1  # Maximum difference in pod count between zones
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule  # or ScheduleAnyway
        labelSelector:
          matchLabels:
            app: webapp
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# Example 2: Spread across nodes
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-spread-nodes
spec:
  replicas: 9
  selector:
    matchLabels:
      app: webapp-nodes
  template:
    metadata:
      labels:
        app: webapp-nodes
    spec:
      # Spread pods evenly across nodes
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: webapp-nodes
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# Example 3: Multiple topology constraints
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-multi-topology
spec:
  replicas: 12
  selector:
    matchLabels:
      app: webapp-multi
  template:
    metadata:
      labels:
        app: webapp-multi
        tier: frontend
    spec:
      # Spread across both zones and nodes
      topologySpreadConstraints:
      # First, spread across zones
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: webapp-multi
      # Then, spread across nodes within zones
      - maxSkew: 2
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app: webapp-multi
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# Example 4: Topology spread with minDomains
# Kubernetes 1.25+ feature
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-min-domains
spec:
  replicas: 6
  selector:
    matchLabels:
      app: webapp-mindomain
  template:
    metadata:
      labels:
        app: webapp-mindomain
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        minDomains: 3  # Ensure pods are spread across at least 3 zones
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: webapp-mindomain
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# Example 5: Topology spread with node affinity
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-spread-affinity
spec:
  replicas: 6
  selector:
    matchLabels:
      app: webapp-affinity
  template:
    metadata:
      labels:
        app: webapp-affinity
    spec:
      # Combine topology spread with node affinity
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: webapp-affinity
      
      # Only schedule on nodes with SSD storage
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
      
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# Example 6: Custom topology domain
# Spread across custom labels (e.g., rack, datacenter)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-custom-topology
spec:
  replicas: 8
  selector:
    matchLabels:
      app: webapp-custom
  template:
    metadata:
      labels:
        app: webapp-custom
    spec:
      topologySpreadConstraints:
      # Spread across custom rack labels
      - maxSkew: 2
        topologyKey: rack  # Custom label on nodes
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app: webapp-custom
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# Example 7: StatefulSet with topology spread
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: cassandra
spec:
  serviceName: cassandra
  replicas: 9
  selector:
    matchLabels:
      app: cassandra
  template:
    metadata:
      labels:
        app: cassandra
    spec:
      # Spread Cassandra nodes across zones for HA
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: cassandra
      containers:
      - name: cassandra
        image: cassandra:4.1
        ports:
        - containerPort: 9042
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: data
          mountPath: /var/lib/cassandra
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi

---
# Example 8: Comparison with Pod Anti-Affinity
# Topology spread is more flexible than anti-affinity

# Old way: Pod Anti-Affinity (all or nothing)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-antiaffinity
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp-aa
  template:
    metadata:
      labels:
        app: webapp-aa
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: webapp-aa
            topologyKey: kubernetes.io/hostname
      containers:
      - name: webapp
        image: nginx:1.25-alpine

---
# New way: Topology Spread (more flexible)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-topology
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp-ts
  template:
    metadata:
      labels:
        app: webapp-ts
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway  # More flexible than anti-affinity
        labelSelector:
          matchLabels:
            app: webapp-ts
      containers:
      - name: webapp
        image: nginx:1.25-alpine
